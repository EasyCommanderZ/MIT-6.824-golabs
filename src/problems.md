# 一些可能的问题 & 优化



## Lab 4

- Lab 中为了统一接口，把RPC的消息体设计的比较大。但是这样简化了很多的代码逻辑。
- 所有的设计状态机变更的操作都要通过日志的方式提交，并且由leader来执行
- 对于每个 raft 组的 leader ，需要有一个协程去向master定时拉取最新的配置，如果获得了新的配置就进行更新。为了防止集群的分片状态被覆盖，一旦存在有分片的状态不是默认状态，马上停止获取和提交新配置直到所有分片都变为默认状态；
- challenge 2 要求apply协程不被阻塞，还要求配置的更新和分片的状态变化彼此独立，所以很显然，我们不能在配置更新的同时去拉取数据，也不能异步的去拉取数据并当作一条raft日志提交，而是应该将不同raft组所属的分片数据独立起来，分别提交多条日志来维护状态。因此shardKV需要对每个分片维护一些额外的状态变量
- 我们不能在 apply 配置的时候启动异步任务，而是只更新 shard 状态，由单独的协程去执行分片迁移和清理等任务。为了能够知道数据的流向，我们需要保存上一次的配置，lastConfig。
- 在节点频繁重启后，出现了空日志的必要性的问题。这导致某一 raft 组的状态机无法达到最新且不全是默认状态，使得更新协程无法提交新的配置日志，此时客户端碰巧没有向他执行读写请求，因而该 raft 组使用没有当前 term 的日志，从而无法推进 commitIndex，使得整个集群出现了活锁。
  该 bug 的解决方法很简单，就是让 raft 层的 leader 在 kv 层周期性的去检测下层是否包含当前 term 的日志，如果没有便 append 一条空日志，这样即可保证新选出的 leader 状态机能够迅速达到最新。
